version: 1

# Per-engine query limits (applied before executing individual queries)
query_limits:
  duckdb:
    max_bytes: 5_000_000
  postgres:
    max_bytes: 10_000_000
  bigquery:
    max_bytes: 50_000_000
  databricks_spark:
    max_bytes: 50_000_000
  snowflake_snowpark:
    max_bytes: 50_000_000

# Global limits across the entire fft run
total:
  bytes_scanned:
    # ~10 MB – adjust down if you want to force a warning
    warn: 100
    # ~100 MB – adjust down if you want to force an error
    error: 100_000_000

  # Optional: total query time across all queries in the run
  query_duration_ms:
    warn: "30s"   # human-friendly duration, parsed to ms
    error: "2m"

# Per-model limits (keys must match node names: stg_users.ff, mart_user_orders.ff, http_users, ...)
models:
  stg_users.ff:
    bytes_scanned:
      # keep this fairly low so you can see a warn if you want
      warn: 100
      error: 10_000_000

  stg_orders.ff:
    bytes_scanned:
      warn: 1_000_000
      error: 10_000_000

  mart_user_orders.ff:
    bytes_scanned:
      warn: 1_000_000
      error: 100_000_000

  http_users:
    # HTTP model → mainly interesting on engines that can report bytes_scanned
    bytes_scanned:
      warn: 5_000_000
      error: 50_000_000

  py_constants:
    bytes_scanned:
      warn: 5_000_000
      error: 50_000_000

# Per-tag budgets (aggregated over all models with that tag)
tags:
  "example:cache_demo":
    bytes_scanned:
      warn: 10_000_000
